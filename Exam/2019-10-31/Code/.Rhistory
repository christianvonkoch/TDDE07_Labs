help(deviance)
knitr::opts_chunk$set(echo = TRUE)
RNGversion('3.5.1')
Dataframe=read.csv("australian-crabs.csv")
n = length(Dataframe[,1])
CL = Dataframe$CL
RW = Dataframe$RW
plot(CL, RW, main="Plot of carapace length versus rear width depending on sex",
sub="Red = Female, Blue = Male",
col=c("red", "blue")[Dataframe$sex], xlab="CL", ylab="RW")
#Create function for misclassification rate
missclass=function(conf_matrix, fit_matrix){
n=length(fit_matrix[,1])
return(1-sum(diag(conf_matrix))/n)
}
#LDA analysis with target Sex, and features CL and RW and proportional prior
library("MASS")
model = lda(sex ~ CL+RW, data=Dataframe)
predicted = predict(model, data=Dataframe)
confusion_matrix = table(Dataframe$sex, predicted$class)
misclass = missclass(confusion_matrix, Dataframe)
print(confusion_matrix)
print(misclass)
plot(CL, RW, main="Plot values of CL and RW depending on predicted sex",
sub="Red = Female, Blue = Male",
col=c("red", "blue")[predicted$class], xlab="CL", ylab="RW")
#Repeat step 2 but use priors p(Male)=0.9 and p(Female)=0.1
model2 = lda(sex ~ CL+RW, data=Dataframe, prior=c(1,9)/10)
predicted2 = predict(model2, data=Dataframe)
confusion_matrix2 = table(Dataframe$sex, predicted2$class)
misclass2 = missclass(confusion_matrix2, Dataframe)
print(confusion_matrix2)
print(misclass2)
plot(CL, RW, main="Predicted values of CL and RW with priors 0.9 (male) 0.1 (female)"
, sub="Red = Female, Blue = Male", col=c("red", "blue")[predicted2$class], xlab="CL",
ylab="RW")
#Repeat step 2 but now with logistic regression
model3 = glm(sex ~ CL+RW, data=Dataframe, family='binomial')
predicted3 = predict(model3, newdata=Dataframe, type='response')
sexvector = c()
for (i in predicted3) {
if (i>0.5) {
sexvector = c(sexvector, 'Male')
} else {
sexvector = c(sexvector, 'Female')
}
}
sexvector_factor = as.factor(sexvector)
confusion_matrix3 = table(Dataframe$sex, sexvector_factor)
misclass3 = missclass(confusion_matrix3, Dataframe)
print(confusion_matrix3)
print(misclass3)
plot(CL, RW, main="Predicted values of CL and RW but with logistic regression",
col=c("red", "blue")[sexvector_factor], xlab="CL", ylab="RW", xlim=c(0,50),
ylim=c(0,20))
boundaryline = function(length, coefficientvector, prior) {
return(-coefficientvector[1]/coefficientvector[3]-
(coefficientvector[2]/coefficientvector[3])*length+
log(prior/(1-prior))/coefficientvector[3])
}
par(new=TRUE)
curve(boundaryline(x, model3$coefficients, 0.5), xlab="CL", ylab="RW", col="green",
from=0, to=50, xlim=c(0,50), ylim=c(0,20),
sub="Red = Female, Blue = Male, Green = Boundaryline")
#1: Read data and divide into train, validation and test sets
library("tree")
data=read.csv2("creditscoring.csv")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
id1=setdiff(1:n, id)
set.seed(12345)
id2=sample(id1, floor(n*0.25))
valid=data[id2,]
id3=setdiff(id1,id2)
test=data[id3,]
#Create function for misclassification rate
misclass=function(conf_matrix, fit_matrix){
n=length(fit_matrix[,1])
return(1-sum(diag(conf_matrix))/n)
}
#2: Fit a decision tree to train data using the measures of impurity gini and deviance.
#Report misclass rates and choose optimal measure moving forward.
fit_deviance=tree(good_bad~., data=train, split="deviance")
predicted_deviance=predict(fit_deviance, newdata=test, type="class")
confusionmatrix_deviance=table(test$good_bad, predicted_deviance)
misclass_deviance=misclass(confusionmatrix_deviance, test)
print(confusionmatrix_deviance)
print(misclass_deviance)
fit_gini=tree(good_bad~., data=train, split="gini")
predicted_gini=predict(fit_gini, newdata=test, type="class")
confusionmatrix_gini=table(test$good_bad, predicted_gini)
misclass_gini=misclass(confusionmatrix_gini, test)
print(confusionmatrix_gini)
print(misclass_gini)
#Deviance has best misclass score
#3: Use training and valid data to choose optimal tree depth. Present graphs of the
#dependence of deviances for training and validation data on the number of leaves.
#Report optimal tree, report it's depth and variables used bytree. Estimate
#misclassification rate for the test data.
fit_optimaltree=tree(good_bad~., data=train, split="deviance")
summary(fit_optimaltree)
trainScore=rep(0,15)
testScore=rep(0,15)
for(i in 2:15){
prunedTree=prune.tree(fit_optimaltree, best=i)
pred=predict(prunedTree, newdata=valid, type="tree")
#Divide by two since double of data points
trainScore[i]=deviance(prunedTree)/2
testScore[i]=deviance(pred)
}
plot(2:15, trainScore[2:15], type="b", col="red", ylim=c(200,500))
points(2:15, testScore[2:15], type="b", col="blue")
min_deviance=min(testScore[2:15])
print(min_deviance)
optimal_leaves=which(testScore[1:15] == min_deviance)
print(optimal_leaves)
#Optimal no of leaves is 4
finalTree=prune.tree(fit_optimaltree, best=4)
plot(finalTree)
text(finalTree, pretty=0)
#Final tree contains variables savings, duration and history. Since 3 vars => Depth of
#tree is 3.
predicted_test=predict(finalTree, newdata=test, type="class")
confusionmatrix_test=table(test$good_bad, predicted_test)
misclass_test=misclass(confusionmatrix_test, test)
print(confusionmatrix_test)
print(misclass_test)
#4: Use traning data to perform classification using Naives bayes and report the confusion
#matrices and misclassification rates for the traning and for the test data. Compare with
#results from previous steps.
#Load libraries
library(MASS)
library(e1071)
fit_naive=naiveBayes(good_bad~., data=train)
#Create function for predicting and creating confusion matrice and printing
#misclassification rate
compute_naive=function(model,data){
predictedNaive=predict(model, newdata=data, type="class")
confusionmatrixNaive=table(data$good_bad,predictedNaive)
misclass = misclass(confusionmatrixNaive, data)
print(confusionmatrixNaive)
print(misclass)
return(predictedNaive)
}
predictedNaive_train=compute_naive(fit_naive,train)
predictedNaive_test=compute_naive(fit_naive, test)
#5: Use optimal tree and Naives Bayes to classify the test data by using principle:
#classified as 1 if bigger than 0.05, 0.1, 0.15, ..., 0.9, 0.95. Compute the TPR
#and FPR for two models and plot corresponsing ROC curves.
#Writing function for classifying data
class=function(data, class1, class2, prior){
vector=c()
for(i in data) {
if(i>prior){
vector=c(vector,class1)
} else {
vector=c(vector,class2)
}
}
return(vector)
}
x_vector=seq(0.05,0.95,0.05)
tpr_tree=c()
fpr_tree=c()
tpr_naive=c()
fpr_naive=c()
treeVector=c()
treeConfusion = c()
naiveConfusion = c()
treeClass = c()
naiveClass = c()
#Reusing optimal tree found in task 3 but returntype is response instead
predictTree=data.frame(predict(finalTree, newdata=test, type="vector"))
predictNaive=data.frame(predict(fit_naive, newdata=test, type="raw"))
for(prior in x_vector){
treeClass = class(predictTree$good, 'good', 'bad', prior)
treeConfusion=table(test$good_bad, treeClass)
if(ncol(treeConfusion)==1){
if(colnames(treeConfusion)=="good"){
treeConfusion=cbind(c(0,0), treeConfusion)
} else {
treeConfusion=cbind(treeConfusion,c(0,0))
}
}
totGood=sum(treeConfusion[2,])
totBad=sum(treeConfusion[1,])
tpr_tree=c(tpr_tree, treeConfusion[2,2]/totGood)
fpr_tree=c(fpr_tree, treeConfusion[1,2]/totBad)
naiveClass=class(predictNaive$good, 'good', 'bad', prior)
naiveConfusion=table(test$good_bad, naiveClass)
if(ncol(naiveConfusion)==1){
if(colnames(naiveConfusion)=="good"){
naiveConfusion=cbind(c(0,0), naiveConfusion)
} else {
naiveConfusion=cbind(naiveConfusion,c(0,0))
}
}
totGood=sum(naiveConfusion[2,])
totBad=sum(naiveConfusion[1,])
tpr_naive=c(tpr_naive, naiveConfusion[2,2]/totGood)
fpr_naive=c(fpr_naive, naiveConfusion[1,2]/totBad)
}
#Plot the ROC curves
plot(fpr_naive, tpr_naive, main="ROC curve", sub="Red = Naive Bayes, Blue = Tree",
type="l", col="red", xlim=c(0,1), ylim=c(0,1), xlab="FPR", ylab="TPR")
points(fpr_tree, tpr_tree, type="l", col="blue")
#Naive has greatest AOC => should choose Naive
#6: Repeate Naive Bayes with loss matrix punishing with factor 10 if predicting good when
#bad and 1 if predicting bad when good.
naiveModel=naiveBayes(good_bad~., data=train)
train_loss=predict(naiveModel, newdata=train, type="raw")
test_loss=predict(naiveModel, newdata=test, type="raw")
confusion_trainLoss=table(train$good_bad, ifelse(train_loss[,2]/train_loss[,1]>10, "good",
"bad"))
misclass_trainLoss=misclass(confusion_trainLoss, train)
print(confusion_trainLoss)
print(misclass_trainLoss)
confusion_testLoss=table(test$good_bad, ifelse(test_loss[,2]/test_loss[,1]>10, "good",
"bad"))
misclass_testLoss=misclass(confusion_testLoss, test)
print(confusion_testLoss)
print(misclass_testLoss)
#1: Read data
data=read.csv2("NIRspectra.csv")
data$Viscosity=c()
n=dim(data)[1]
#1: Conduct standard PCA using the feature space and provide a plot explaining how much
#variation is explained by each feature. Provide plot that show the scores of PC1 vs PC2.
#Are there unusual diesel fuels according to this plot.
pcaAnalysis=prcomp(data)
#Eigenvalues
lambda=pcaAnalysis$sdev^2
#Proportion of variation
propVar= lambda/sum(lambda)*100
screeplot(pcaAnalysis, main="Total variation from PCA components")
noOfVars=1
sumOfVariation=propVar[noOfVars]
while(sumOfVariation<99){
noOfVars=noOfVars+1
sumOfVariation=sumOfVariation+propVar[noOfVars]
}
#Print number of variables used and total variation
print(noOfVars)
print(sumOfVariation)
#Print PC1 and PC2 in plot
plot(pcaAnalysis$x[,1],pcaAnalysis$x[,2], type="p", col="blue", main="PC1 vs PC2",
xlab="PC1", ylab="PC2")
#We can see from the graph that the data is very accurately described by PC1.
#2: Make trace plots of the loadings of the components selected in step 1. Is there any
#principle component that is explaines by mainly a few original features?
U=pcaAnalysis$rotation
plot(U[,1], main="Traceplot, PC1", xlab="index", ylab="PC1", type="b")
plot(U[,2], main="Traceplot, PC2", xlab="index", ylab="PC2", type="b")
#We can see from graph that PC2 is not described by so many original features since it is
#close to zero for many of the features. The last 30 or so variables have an effect on PC2.
#3: Perform independent Component Analysis (ICA) with no of components selected in step1
#(set seed 12345). Check the documentation of R for fastICA method and do following:
# Compute W'=K*W and present columns of W' in form of the trace plots. Compare with trace
# plots in step 2 and make conclusions. What kind of measure is represented by the matrix W'.
# Make a plot of the scores of the first two latent features and compare it with the score
# plot from step 1.
#Install package fastICa
#install.packages("fastICA")
library("fastICA")
set.seed(12345)
icaModel = fastICA(data, n.comp=2, verbose=TRUE)
W=icaModel$W
K=icaModel$K
W_est=K%*%W
plot(W_est[,1], main="Traceplot, ICA1", xlab="index", ylab="ICA1", type="b", col="red")
plot(W_est[,2], main="Traceplot, ICA2", xlab="index", ylab="ICA2", type="b", col="red")
#Compared to the plots in step 2 the ICA1 follows in roughly the same pattern as PCA2
#and ICA2 the same as PCA1.
plot(icaModel$S[,1], icaModel$S[,2], main="ICA1 vs ICA2", xlab="ICA1", ylab="ICA2",
type="p", col="blue")
#We can see from the plot that the dat is pretty well described by ICA2 whereas ICA1 is
#not that significant in describing the data (since it is close to 0 most of the cases).
#Some outliers are however described by ICA1.
help("glm")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
View(results_matrix)
source('~/.active-rstudio-document', echo=TRUE)
View(results_matrix)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
View(results_matrix)
source('~/.active-rstudio-document', echo=TRUE)
View(results_matrix)
source('~/.active-rstudio-document', echo=TRUE)
View(results_matrix)
source('~/.active-rstudio-document', echo=TRUE)
View(results_matrix)
source('~/.active-rstudio-document', echo=TRUE)
View(results_matrix)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
help(index)
??index
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
library(rstan)
x=rep(0,T)
y=rep(0,T)
x=AR_process_function(mu, sigma_sq, T, 0.3)
y=AR_process_function(mu, simga_sq, T, 0.95)
y=AR_process_function(mu, sigma_sq, T, 0.95)
?stan
library(rstan)
x=rep(0,T)
y=rep(0,T)
x=AR_process_function(mu, sigma_sq, T, 0.3)
y=AR_process_function(mu, sigma_sq, T, 0.95)
StanModel= '
data {
int<lower=0> N;
vector[N] y;
vector[N] x;
}
parameters {
real mu;
real phi;
real<lower=0> sigma;
}
model {
for (n in 2:N)
y[n] ~ normal(mu + phi * (y[n-1]-mu), sigma);
x[n] ~ normal(mu + phi * (x[n-1]-mu), sigma)
}
'
data=list(N=T, y=y, x=x, P=2)
fit=stan(model_code=StanModel, data=data)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
View(fit_x)
print(fit_x,digits_summary=3)
postDraws <- extract(fit_x)
View(postDraws)
postDraws_y <- extract(fit_y)
postDraws_x <- extract(fit_x)
View(fit_x)
View(fit_x)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
help("print.stanfit")
# Do traceplots of the first chain
par(mfrow = c(1,1))
plot(postDraws_x$mu[1000:2000],type="l",ylab="mu",main="Traceplot")
# Do automatic traceplots of all chains
traceplot(fit_x)
# Bivariate posterior plots
pairs(fit_x)
help(par)
View(postDraws_x)
# Do traceplots of the first chain
par(mfrow = c(1,1))
plot(postDraws_x$mu[1000:2000], postDraws_x$phi[1000:2000], type="l",ylab="mu",main="Traceplot")
# Do automatic traceplots of all chains
traceplot(fit_x)
# Do traceplots of the first chain
par(mfrow = c(1,1))
plot(postDraws_x$mu[1000:2000], postDraws_x$phi[1000:2000], type="l",ylab="mu",main="Traceplot")
plot(postDraws_x$mu[1000:2000], postDraws_x$phi[1000:2000],ylab="mu",main="Traceplot")
# Do automatic traceplots of all chains
traceplot(fit_x)
# Bivariate posterior plots
pairs(fit_x)
# Do traceplots of the first chain
par(mfrow = c(1,1))
plot(postDraws_y$mu[1000:2000],postDraws_x$phi[1000:2000],ylab="mu",main="Traceplot")
# Do automatic traceplots of all chains
traceplot(fit_y)
# Bivariate posterior plots
pairs(fit_y)
plot(postDraws_x$mu[1000:2000], postDraws_x$phi[1000:2000],ylab="mu",main="Traceplot", type="l")
plot(plot(postDraws_x$mu[1000:2000])
plot(postDraws_x$mu[1000:2000])
plot(postDraws_x$mu[1000:2000])
plot(postDraws_x$mu[1000:2000], type="l")
plot(postDraws_y$mu[1000:2000],postDraws_x$phi[1000:2000],ylab="mu",main="Traceplot")
plot(postDraws_y$mu[1000:2000])
plot(postDraws_y$mu[1000:2000],postDraws_y$phi[1000:2000],ylab="mu", xlab="mu",main="Traceplot")
plot(postDraws_y$phi[1000:2000])
plot(postDraws_y$mu[1000:2000])
plot(postDraws_x$mu[1000:2000], postDraws_x$phi[1000:2000],ylab="phi", xlab="mu", main="Traceplot", type="l")
plot(postDraws_x$mu[1000:2000], postDraws_x$phi[1000:2000],ylab="phi", xlab="mu", main="Traceplot")
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab4/Lab4_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/MathExercise3_3.R', echo=TRUE)
alpha = 1
beta = 1
n = 6
s = 1
f = n-s
normalMean = (alpha + s - 1)/(alpha+beta+n-2)
normalVar = (alpha + s - 1)*(beta + f - 1)/(alpha + beta + n - 2)^3
xgrid = seq(0,1,.001)
plot(xgrid,dbeta(xgrid,alpha+s,beta+f),type="l")
lines(xgrid,dnorm(xgrid,normalMean,sqrt(normalVar)),col=2)
legend("topright", box.lty = 1, legend = c("Beta posterior","Normal approx."),
col = c("black",'red'), lwd = 2)
# 3d
alpha = 1
beta = 1
n = 600
s = 100
f = n-s
normalMean = (alpha + s - 1)/(alpha+beta+n-2)
normalVar = (alpha + s - 1)*(beta + f - 1)/(alpha + beta + n - 2)^3
xgrid = seq(0,1,.001)
plot(xgrid,dbeta(xgrid,alpha+s,beta+f),type="l")
lines(xgrid,dnorm(xgrid,normalMean,sqrt(normalVar)),col=2)
legend("topright", box.lty = 1, legend = c("Beta posterior","Normal approx."),
col = c("black",'red'), lwd = 2)
abs(2==2)
abs(2==3)
setwd("~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2019-08-21")
setwd("~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab2")
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Lab2/Lab2_Assignment1.R', echo=TRUE)
help(colquantile)
?colmeans
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2018-08-22/2018-08-22_Assignment1.R', echo=TRUE)
setwd("~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2018-08-22")
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2018-08-22/2018-08-22_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2018-08-22/Code/ExamData.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2018-08-22/2018-08-22_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2018-08-22/2018-08-22_Assignment1.R', echo=TRUE)
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2018-08-22/2018-08-22_Assignment1.R', echo=TRUE)
pred_lion=rep(0, length(mu_post))
help(lrnorm)
?rlnorm
pred_lion=rep(0, length(mu_post))
for (i in 1:length(mu_post)) {
pred_lion=rlnorm(1, mu_post[i], sigma2_post[i])
}
mean(pred_lion)
estimate=exp(mu_post+1/2*sigma2_post)
mean(estimate)
setwd("~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2019-10-31/Code")
source('~/SKOLA/LIU/Åk 4/TDDE07/TDDE07_Labs/Exam/2019-10-31/Code/ExamData.R', echo=TRUE)
View(cars)
