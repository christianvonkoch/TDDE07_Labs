drawX=rchisq(nDraws, v0)
sigma_sq=(v0)*sigma0_sq/drawX
betaMatrix=matrix(0,nDraws,3)
# Create new plot with specific settings so that the loop can overlay plots
plot.new()
plot.window(xlim=c(0,1), ylim=c(-50,50))
axis(side=1)
axis(side=2)
set.seed(12345)
for (i in 1:nDraws) {
betaMatrix[i,]=drawBeta(my0, sigma_sq[i], omega0Inv)
lines(temp$time, calcRegr(betaMatrix, i, temp$time), col=rgb(0,0,0,0.2))
}
title(main="Temperatures depending on times for different simulated models", xlab="Time",
ylab="Temp")
# Calculating the parameters for the posterior distribution
v_n=v0+length(temp$temp)
X=cbind(1, temp$time, temp$time^2)
Y=temp$temp
beta_hat=solve(t(X)%*%X)%*%t(X)%*%Y
my_n=solve(t(X)%*%X+omega0)%*%(t(X)%*%X%*%beta_hat+omega0%*%my0)
omega_n=t(X)%*%X+omega0
omega_n_Inv=solve(omega_n)
sigma_sq_n=(v0*sigma0_sq+(t(Y)%*%Y+t(my0)%*%omega0%*%my0-t(my_n)%*%omega_n%*%my_n))/v_n
# Simulate the joint posterior
sigma_sq_post=(v_n)*c(sigma_sq_n)/drawX
betaMatrix_post=matrix(0,nDraws,3)
response_post_temp=matrix(0,nDraws,length(temp$time))
for (i in 1:nDraws) {
betaMatrix_post[i,]=drawBeta(my_n, sigma_sq_post[i], omega_n_Inv)
}
# Plots the marginal distributions for the different beta-values
hist(betaMatrix_post[,1], breaks=100, main="Marginal posterior for beta0", xlab="Beta0")
hist(betaMatrix_post[,2], breaks=100, main="Marginal posterior for beta1", xlab="Beta1")
hist(betaMatrix_post[,3], breaks=100, main="Marginal posterior for beta2", xlab="Beta2")
plot(temp$time, Y, main="Plot of the temp data for different times", col="blue",
xlab="Time coefficient", ylab="Temp")
# Applies function calcRegr to the time-values for each of the drawn betas and stores the
# results in matrix
for (i in 1:nDraws) {
betaTemp=sapply(temp$time, calcRegr, betaMatrix=betaMatrix_post, row=i)
response_post_temp[i,]=betaTemp
}
response_post=c()
credInterval=matrix(0, length(temp$time), 2)
# Retrieves the median of the response values as well as obtaining the upper and lower
# bound of credInterval
for (i in 1:length(temp$time)) {
sortedTemp=sort(response_post_temp[,i])
response_post=c(response_post, (sortedTemp[500]+sortedTemp[501])/2)
credInterval[i,]=c(sortedTemp[(0.025*length(sortedTemp)+1)],
sortedTemp[(0.975*length(sortedTemp))])
}
lines(temp$time, response_post)
lines(temp$time, credInterval[,1], col="gray")
lines(temp$time, credInterval[,2], col="gray")
title(sub="Grey = 95 % credible intervals, Black = Median")
# Function for calculating the time-value which yields the maximum response (the derivative
# of response function)
calcMaxTemp = function(betaMatrix, row) {
return(-betaMatrix[row,2]/(2*betaMatrix[row,3]))
}
# For each of the draws the time-value which yields the maximum temperature is stored in
# a vector
time_max_temp=c()
for (i in 1:nDraws) {
time_max_temp=c(time_max_temp, calcMaxTemp(betaMatrix_post, i))
}
hist(time_max_temp, breaks=1000, xlim=c(0,1), main="Frequency of max temperatures simulated
from xtilde", xlab="Time")
# Use of libraries
library(mvtnorm)
# Read data
WomenWork = read.table("WomenWork.dat", header=TRUE)
# User input
tau = 10
# Defining vectors X and Y
X = as.matrix(WomenWork[,2:ncol(WomenWork)])
Y = WomenWork[,1]
nFeatures = dim(X)[2]
covNames=names(WomenWork[,2:ncol(WomenWork)])
# Constructing prior
mu_prior = rep(0,nFeatures)
sigma_prior = tau^2*diag(nFeatures)
# Defining function for returning the log posterior
logPostLogistic = function(beta, Y, X, mu, sigma) {
nFeat = length(beta)
XBeta=X%*%beta
# Defining loglikelihood
logLike = sum(Y*XBeta-log(1+exp(XBeta)))
# Defining prior
prior = dmvnorm(beta, mean=mu, sigma=sigma, log=TRUE)
# Adding loglikelihood and logprior together. Since it is log both of them are added
# instead of multiplied
return(logLike + prior)
}
# Defining initial values to be passed on to the optimizer
set.seed(12345)
initVals = rnorm(dim(X)[2])
# Finding the optimized betavector
optimResult = optim(initVals, logPostLogistic, Y=Y, X=X, mu=mu_prior, sigma=sigma_prior,
method=c("BFGS"), control=list(fnscale=-1), hessian=TRUE)
# Defining the values of interest
postMode = optimResult$par
postCov = -solve(optimResult$hessian)
names(postMode) = covNames
approx_PostStd = sqrt(diag(postCov))
names(approx_PostStd) = covNames
print("The posterior mode is:")
print(postMode)
print("The approximated standard deviations are:")
print(approx_PostStd)
# Compute marginal distribution for nSmallChild
NSmallChild_mode = as.numeric(postMode["NSmallChild"])
NSmallChild_std = as.numeric(approx_PostStd["NSmallChild"])
set.seed(12345)
NSmallChild_distrib = rnorm(10000, mean=NSmallChild_mode, sd=NSmallChild_std)
sorted_NSmallChild=sort(NSmallChild_distrib)
credInterval_NSmallChild = c(sorted_NSmallChild[(0.025*length(sorted_NSmallChild)+1)],
sorted_NSmallChild[(0.975*length(sorted_NSmallChild))])
print(paste("The lower bound of the 95 % credible interval for the feature NSmallChild is",
round(credInterval_NSmallChild[1], 6)))
print(paste( "The upper bound of the 95 % credible interval for the feature NSmallChild is",
round(credInterval_NSmallChild[2], 6)))
# Verify that the calculations have been made correctly
glmModel = glm(Work ~ 0+., data=WomenWork, family=binomial)
print("The coefficients for the glmmodel using maximum likelihood are:")
print(glmModel$coefficients)
print("The coefficients calculated by the optimizer function with the approximated distribution are:")
print(postMode)
sigmoid = function(value) {
return (exp(value)/(1+exp(value)))
}
makePredLogReg = function(data, mean, sigma, nDraws) {
betaPred = rmvnorm(nDraws, mean=mean, sigma=sigma)
linearPred = betaPred %*% data
logPred = sigmoid(linearPred)
return(logPred)
}
nDraws=10000
woman=c(1, 10, 8, 10, (10/10)^2, 40, 1, 1)
set.seed(12345)
womanWorkPred=makePredLogReg(woman, postMode, postCov, nDraws)
plot(density(womanWorkPred), main="Density of the predicted probabilities",
xlab="Probability", ylab="Density")
makePredLogRegMultiple = function(data, mean, sigma, nDraws, n) {
multiplePred=c()
for (i in 1:nDraws) {
betaDraw = makePredLogReg(data, mean, sigma, 1)
multiplePred=c(multiplePred, rbinom(1, n, betaDraw))
}
hist(multiplePred, breaks=100, main=paste("Distribution for prediction made on", n, "women"),
xlab="No. of women")
}
makePredLogRegMultiple(woman, postMode, postCov, 10000, 10)
plot(temp$time, Y, main="Plot of the temp data for different times", col="blue",
xlab="Time coefficient", ylab="Temp")
source('~/SKOLA/LIU/Ã…k 4/TDDE07/TDDE07_Labs/Lab2/Lab2_Assignment1.R', echo=TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Read file
temp = read.table("TempLinkoping.txt", header=TRUE)
## install.packages("mvtnorm")
library(mvtnorm)
# Defining the parameters for the prior distribution
# Switched to beta0=0 since it seems more reasonable and -10 seems too low.
my0=c(0,100,-100)
omega0=0.01*diag(3)
v0=4
sigma0_sq=1
omega0Inv=solve(omega0)
# Function for returning the response variable
calcRegr = function(betaMatrix, row, x) {
return(betaMatrix[row,1]+betaMatrix[row,2]*x+betaMatrix[row,3]*x^2)
}
# Function for drawing simulated betavalues
drawBeta = function(my, sigma_sq, omegaInv) {
return(rmvnorm(1, mean=my, sigma=sigma_sq*omegaInv))
}
nDraws=1000
set.seed(12345)
drawX=rchisq(nDraws, v0)
sigma_sq=(v0)*sigma0_sq/drawX
betaMatrix=matrix(0,nDraws,3)
# Create new plot with specific settings so that the loop can overlay plots
plot.new()
plot.window(xlim=c(0,1), ylim=c(-50,50))
axis(side=1)
axis(side=2)
set.seed(12345)
for (i in 1:nDraws) {
betaMatrix[i,]=drawBeta(my0, sigma_sq[i], omega0Inv)
lines(temp$time, calcRegr(betaMatrix, i, temp$time), col=rgb(0,0,0,0.2))
}
title(main="Temperatures depending on times for different simulated models", xlab="Time",
ylab="Temp")
# Calculating the parameters for the posterior distribution
v_n=v0+length(temp$temp)
X=cbind(1, temp$time, temp$time^2)
Y=temp$temp
beta_hat=solve(t(X)%*%X)%*%t(X)%*%Y
my_n=solve(t(X)%*%X+omega0)%*%(t(X)%*%X%*%beta_hat+omega0%*%my0)
omega_n=t(X)%*%X+omega0
omega_n_Inv=solve(omega_n)
sigma_sq_n=(v0*sigma0_sq+(t(Y)%*%Y+t(my0)%*%omega0%*%my0-t(my_n)%*%omega_n%*%my_n))/v_n
# Simulate the joint posterior
sigma_sq_post=(v_n)*c(sigma_sq_n)/drawX
betaMatrix_post=matrix(0,nDraws,3)
response_post_temp=matrix(0,nDraws,length(temp$time))
for (i in 1:nDraws) {
betaMatrix_post[i,]=drawBeta(my_n, sigma_sq_post[i], omega_n_Inv)
}
# Plots the marginal distributions for the different beta-values
hist(betaMatrix_post[,1], breaks=100, main="Marginal posterior for beta0", xlab="Beta0")
hist(betaMatrix_post[,2], breaks=100, main="Marginal posterior for beta1", xlab="Beta1")
hist(betaMatrix_post[,3], breaks=100, main="Marginal posterior for beta2", xlab="Beta2")
plot(temp$time, temp$temp, main="Plot of the temp data for different times", col="blue",
xlab="Time coefficient", ylab="Temp")
# Applies function calcRegr to the time-values for each of the drawn betas and stores the
# results in matrix
for (i in 1:nDraws) {
betaTemp=sapply(temp$time, calcRegr, betaMatrix=betaMatrix_post, row=i)
response_post_temp[i,]=betaTemp
}
response_post=c()
credInterval=matrix(0, length(temp$time), 2)
# Retrieves the median of the response values as well as obtaining the upper and lower
# bound of credInterval
for (i in 1:length(temp$time)) {
sortedTemp=sort(response_post_temp[,i])
response_post=c(response_post, (sortedTemp[500]+sortedTemp[501])/2)
credInterval[i,]=c(sortedTemp[(0.025*length(sortedTemp)+1)],
sortedTemp[(0.975*length(sortedTemp))])
}
lines(temp$time, response_post)
lines(temp$time, credInterval[,1], col="gray")
lines(temp$time, credInterval[,2], col="gray")
title(sub="Grey = 95 % credible intervals, Black = Median")
# Function for calculating the time-value which yields the maximum response (the derivative
# of response function)
calcMaxTemp = function(betaMatrix, row) {
return(-betaMatrix[row,2]/(2*betaMatrix[row,3]))
}
# For each of the draws the time-value which yields the maximum temperature is stored in
# a vector
time_max_temp=c()
for (i in 1:nDraws) {
time_max_temp=c(time_max_temp, calcMaxTemp(betaMatrix_post, i))
}
hist(time_max_temp, breaks=1000, xlim=c(0,1), main="Frequency of max temperatures simulated
from xtilde", xlab="Time")
# Use of libraries
library(mvtnorm)
# Read data
WomenWork = read.table("WomenWork.dat", header=TRUE)
# User input
tau = 10
# Defining vectors X and Y
X = as.matrix(WomenWork[,2:ncol(WomenWork)])
Y = WomenWork[,1]
nFeatures = dim(X)[2]
covNames=names(WomenWork[,2:ncol(WomenWork)])
# Constructing prior
mu_prior = rep(0,nFeatures)
sigma_prior = tau^2*diag(nFeatures)
# Defining function for returning the log posterior
logPostLogistic = function(beta, Y, X, mu, sigma) {
nFeat = length(beta)
XBeta=X%*%beta
# Defining loglikelihood
logLike = sum(Y*XBeta-log(1+exp(XBeta)))
# Defining prior
prior = dmvnorm(beta, mean=mu, sigma=sigma, log=TRUE)
# Adding loglikelihood and logprior together. Since it is log both of them are added
# instead of multiplied
return(logLike + prior)
}
# Defining initial values to be passed on to the optimizer
set.seed(12345)
initVals = rnorm(dim(X)[2])
# Finding the optimized betavector
optimResult = optim(initVals, logPostLogistic, Y=Y, X=X, mu=mu_prior, sigma=sigma_prior,
method=c("BFGS"), control=list(fnscale=-1), hessian=TRUE)
# Defining the values of interest
postMode = optimResult$par
postCov = -solve(optimResult$hessian)
names(postMode) = covNames
approx_PostStd = sqrt(diag(postCov))
names(approx_PostStd) = covNames
print("The posterior mode is:")
print(postMode)
print("The approximated standard deviations are:")
print(approx_PostStd)
# Compute marginal distribution for nSmallChild
NSmallChild_mode = as.numeric(postMode["NSmallChild"])
NSmallChild_std = as.numeric(approx_PostStd["NSmallChild"])
set.seed(12345)
NSmallChild_distrib = rnorm(10000, mean=NSmallChild_mode, sd=NSmallChild_std)
sorted_NSmallChild=sort(NSmallChild_distrib)
credInterval_NSmallChild = c(sorted_NSmallChild[(0.025*length(sorted_NSmallChild)+1)],
sorted_NSmallChild[(0.975*length(sorted_NSmallChild))])
print(paste("The lower bound of the 95 % credible interval for the feature NSmallChild is",
round(credInterval_NSmallChild[1], 6)))
print(paste( "The upper bound of the 95 % credible interval for the feature NSmallChild is",
round(credInterval_NSmallChild[2], 6)))
# Verify that the calculations have been made correctly
glmModel = glm(Work ~ 0+., data=WomenWork, family=binomial)
print("The coefficients for the glmmodel using maximum likelihood are:")
print(glmModel$coefficients)
print("The coefficients calculated by the optimizer function with the approximated distribution are:")
print(postMode)
sigmoid = function(value) {
return (exp(value)/(1+exp(value)))
}
makePredLogReg = function(data, mean, sigma, nDraws) {
betaPred = rmvnorm(nDraws, mean=mean, sigma=sigma)
linearPred = betaPred %*% data
logPred = sigmoid(linearPred)
return(logPred)
}
nDraws=10000
woman=c(1, 10, 8, 10, (10/10)^2, 40, 1, 1)
set.seed(12345)
womanWorkPred=makePredLogReg(woman, postMode, postCov, nDraws)
plot(density(womanWorkPred), main="Density of the predicted probabilities",
xlab="Probability", ylab="Density")
makePredLogRegMultiple = function(data, mean, sigma, nDraws, n) {
multiplePred=c()
for (i in 1:nDraws) {
betaDraw = makePredLogReg(data, mean, sigma, 1)
multiplePred=c(multiplePred, rbinom(1, n, betaDraw))
}
hist(multiplePred, breaks=100, main=paste("Distribution for prediction made on", n, "women"),
xlab="No. of women")
}
makePredLogRegMultiple(woman, postMode, postCov, 10000, 10)
knitr::opts_chunk$set(echo = TRUE)
# Read file
temp = read.table("TempLinkoping.txt", header=TRUE)
## install.packages("mvtnorm")
library(mvtnorm)
# Defining the parameters for the prior distribution
# Switched to beta0=0 since it seems more reasonable and -10 seems too low.
my0=c(0,100,-100)
omega0=0.01*diag(3)
v0=4
sigma0_sq=1
omega0Inv=solve(omega0)
# Function for returning the response variable
calcRegr = function(betaMatrix, row, x) {
return(betaMatrix[row,1]+betaMatrix[row,2]*x+betaMatrix[row,3]*x^2)
}
# Function for drawing simulated betavalues
drawBeta = function(my, sigma_sq, omegaInv) {
return(rmvnorm(1, mean=my, sigma=sigma_sq*omegaInv))
}
nDraws=1000
set.seed(12345)
drawX=rchisq(nDraws, v0)
sigma_sq=(v0)*sigma0_sq/drawX
betaMatrix=matrix(0,nDraws,3)
# Create new plot with specific settings so that the loop can overlay plots
plot.new()
plot.window(xlim=c(0,1), ylim=c(-50,50))
axis(side=1)
axis(side=2)
set.seed(12345)
for (i in 1:nDraws) {
betaMatrix[i,]=drawBeta(my0, sigma_sq[i], omega0Inv)
lines(temp$time, calcRegr(betaMatrix, i, temp$time), col=rgb(0,0,0,0.2))
}
title(main="Temperatures depending on times for different simulated models", xlab="Time",
ylab="Temp")
# Calculating the parameters for the posterior distribution
v_n=v0+length(temp$temp)
X=cbind(1, temp$time, temp$time^2)
Y=temp$temp
beta_hat=solve(t(X)%*%X)%*%t(X)%*%Y
my_n=solve(t(X)%*%X+omega0)%*%(t(X)%*%X%*%beta_hat+omega0%*%my0)
omega_n=t(X)%*%X+omega0
omega_n_Inv=solve(omega_n)
sigma_sq_n=(v0*sigma0_sq+(t(Y)%*%Y+t(my0)%*%omega0%*%my0-t(my_n)%*%omega_n%*%my_n))/v_n
# Simulate the joint posterior
sigma_sq_post=(v_n)*c(sigma_sq_n)/drawX
betaMatrix_post=matrix(0,nDraws,3)
response_post_temp=matrix(0,nDraws,length(temp$time))
for (i in 1:nDraws) {
betaMatrix_post[i,]=drawBeta(my_n, sigma_sq_post[i], omega_n_Inv)
}
# Plots the marginal distributions for the different beta-values
hist(betaMatrix_post[,1], breaks=100, main="Marginal posterior for beta0", xlab="Beta0")
hist(betaMatrix_post[,2], breaks=100, main="Marginal posterior for beta1", xlab="Beta1")
hist(betaMatrix_post[,3], breaks=100, main="Marginal posterior for beta2", xlab="Beta2")
plot(temp$time, Y, main="Plot of the temp data for different times", col="blue",
xlab="Time coefficient", ylab="Temp")
# Applies function calcRegr to the time-values for each of the drawn betas and stores the
# results in matrix
for (i in 1:nDraws) {
betaTemp=sapply(temp$time, calcRegr, betaMatrix=betaMatrix_post, row=i)
response_post_temp[i,]=betaTemp
}
response_post=c()
credInterval=matrix(0, length(temp$time), 2)
# Retrieves the median of the response values as well as obtaining the upper and lower
# bound of credInterval
for (i in 1:length(temp$time)) {
sortedTemp=sort(response_post_temp[,i])
response_post=c(response_post, (sortedTemp[500]+sortedTemp[501])/2)
credInterval[i,]=c(sortedTemp[(0.025*length(sortedTemp)+1)],
sortedTemp[(0.975*length(sortedTemp))])
}
lines(temp$time, response_post)
lines(temp$time, credInterval[,1], col="gray")
lines(temp$time, credInterval[,2], col="gray")
title(sub="Grey = 95 % credible intervals, Black = Median")
# Function for calculating the time-value which yields the maximum response (the derivative
# of response function)
calcMaxTemp = function(betaMatrix, row) {
return(-betaMatrix[row,2]/(2*betaMatrix[row,3]))
}
# For each of the draws the time-value which yields the maximum temperature is stored in
# a vector
time_max_temp=c()
for (i in 1:nDraws) {
time_max_temp=c(time_max_temp, calcMaxTemp(betaMatrix_post, i))
}
hist(time_max_temp, breaks=1000, xlim=c(0,1), main="Frequency of max temperatures simulated
from xtilde", xlab="Time")
# Use of libraries
library(mvtnorm)
# Read data
WomenWork = read.table("WomenWork.dat", header=TRUE)
# User input
tau = 10
# Defining vectors X and Y
X = as.matrix(WomenWork[,2:ncol(WomenWork)])
Y = WomenWork[,1]
nFeatures = dim(X)[2]
covNames=names(WomenWork[,2:ncol(WomenWork)])
# Constructing prior
mu_prior = rep(0,nFeatures)
sigma_prior = tau^2*diag(nFeatures)
# Defining function for returning the log posterior
logPostLogistic = function(beta, Y, X, mu, sigma) {
nFeat = length(beta)
XBeta=X%*%beta
# Defining loglikelihood
logLike = sum(Y*XBeta-log(1+exp(XBeta)))
# Defining prior
prior = dmvnorm(beta, mean=mu, sigma=sigma, log=TRUE)
# Adding loglikelihood and logprior together. Since it is log both of them are added
# instead of multiplied
return(logLike + prior)
}
# Defining initial values to be passed on to the optimizer
set.seed(12345)
initVals = rnorm(dim(X)[2])
# Finding the optimized betavector
optimResult = optim(initVals, logPostLogistic, Y=Y, X=X, mu=mu_prior, sigma=sigma_prior,
method=c("BFGS"), control=list(fnscale=-1), hessian=TRUE)
# Defining the values of interest
postMode = optimResult$par
postCov = -solve(optimResult$hessian)
names(postMode) = covNames
approx_PostStd = sqrt(diag(postCov))
names(approx_PostStd) = covNames
print("The posterior mode is:")
print(postMode)
print("The approximated standard deviations are:")
print(approx_PostStd)
# Compute marginal distribution for nSmallChild
NSmallChild_mode = as.numeric(postMode["NSmallChild"])
NSmallChild_std = as.numeric(approx_PostStd["NSmallChild"])
set.seed(12345)
NSmallChild_distrib = rnorm(10000, mean=NSmallChild_mode, sd=NSmallChild_std)
sorted_NSmallChild=sort(NSmallChild_distrib)
credInterval_NSmallChild = c(sorted_NSmallChild[(0.025*length(sorted_NSmallChild)+1)],
sorted_NSmallChild[(0.975*length(sorted_NSmallChild))])
print(paste("The lower bound of the 95 % credible interval for the feature NSmallChild is",
round(credInterval_NSmallChild[1], 6)))
print(paste( "The upper bound of the 95 % credible interval for the feature NSmallChild is",
round(credInterval_NSmallChild[2], 6)))
# Verify that the calculations have been made correctly
glmModel = glm(Work ~ 0+., data=WomenWork, family=binomial)
print("The coefficients for the glmmodel using maximum likelihood are:")
print(glmModel$coefficients)
print("The coefficients calculated by the optimizer function with the approximated distribution are:")
print(postMode)
sigmoid = function(value) {
return (exp(value)/(1+exp(value)))
}
makePredLogReg = function(data, mean, sigma, nDraws) {
betaPred = rmvnorm(nDraws, mean=mean, sigma=sigma)
linearPred = betaPred %*% data
logPred = sigmoid(linearPred)
return(logPred)
}
nDraws=10000
woman=c(1, 10, 8, 10, (10/10)^2, 40, 1, 1)
set.seed(12345)
womanWorkPred=makePredLogReg(woman, postMode, postCov, nDraws)
plot(density(womanWorkPred), main="Density of the predicted probabilities",
xlab="Probability", ylab="Density")
makePredLogRegMultiple = function(data, mean, sigma, nDraws, n) {
multiplePred=c()
for (i in 1:nDraws) {
betaDraw = makePredLogReg(data, mean, sigma, 1)
multiplePred=c(multiplePred, rbinom(1, n, betaDraw))
}
hist(multiplePred, breaks=100, main=paste("Distribution for prediction made on", n, "women"),
xlab="No. of women")
}
makePredLogRegMultiple(woman, postMode, postCov, 10000, 10)
